{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nimport numpy as np\nimport time\nimport os\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T17:14:58.021971Z","iopub.execute_input":"2025-07-21T17:14:58.022199Z","iopub.status.idle":"2025-07-21T17:15:05.158186Z","shell.execute_reply.started":"2025-07-21T17:14:58.022176Z","shell.execute_reply":"2025-07-21T17:15:05.157626Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T17:15:05.159499Z","iopub.execute_input":"2025-07-21T17:15:05.159796Z","iopub.status.idle":"2025-07-21T17:15:05.225090Z","shell.execute_reply.started":"2025-07-21T17:15:05.159778Z","shell.execute_reply":"2025-07-21T17:15:05.224269Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load and preprocess MNIST dataset\ntransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\ntrain_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\ntest_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T17:15:05.225876Z","iopub.execute_input":"2025-07-21T17:15:05.226122Z","iopub.status.idle":"2025-07-21T17:15:08.951592Z","shell.execute_reply.started":"2025-07-21T17:15:05.226103Z","shell.execute_reply":"2025-07-21T17:15:08.950767Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 9.91M/9.91M [00:00<00:00, 17.8MB/s]\n100%|██████████| 28.9k/28.9k [00:00<00:00, 481kB/s]\n100%|██████████| 1.65M/1.65M [00:00<00:00, 4.42MB/s]\n100%|██████████| 4.54k/4.54k [00:00<00:00, 6.91MB/s]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Define the teacher model (larger CNN)\nclass TeacherModel(nn.Module):\n    def __init__(self):\n        super(TeacherModel, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU()\n        )\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(64 * 7 * 7, 128),\n            nn.ReLU(),\n            nn.Linear(128, 10)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T17:17:17.819654Z","iopub.execute_input":"2025-07-21T17:17:17.819898Z","iopub.status.idle":"2025-07-21T17:17:17.833250Z","shell.execute_reply.started":"2025-07-21T17:17:17.819878Z","shell.execute_reply":"2025-07-21T17:17:17.832661Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Define the student model (smaller CNN)\nclass StudentModel(nn.Module):\n    def __init__(self):\n        super(StudentModel, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2)\n        )\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(16 * 14 * 14, 32),\n            nn.ReLU(),\n            nn.Linear(32, 10)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.classifier(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T17:17:17.833823Z","iopub.execute_input":"2025-07-21T17:17:17.834008Z","iopub.status.idle":"2025-07-21T17:17:17.845793Z","shell.execute_reply.started":"2025-07-21T17:17:17.833992Z","shell.execute_reply":"2025-07-21T17:17:17.845214Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Knowledge distillation loss function\ndef distillation_loss(y_pred, y_true, teacher_logits, temperature=5.0, alpha=0.5):\n    soft_teacher = torch.softmax(teacher_logits / temperature, dim=1)\n    soft_student = torch.softmax(y_pred / temperature, dim=1)\n    \n    # Distillation loss (KL divergence)\n    distillation_ce = nn.KLDivLoss(reduction='batchmean')(torch.log(soft_student), soft_teacher) * (temperature ** 2)\n    \n    # Standard cross-entropy loss\n    standard_ce = nn.CrossEntropyLoss()(y_pred, y_true)\n    \n    return alpha * distillation_ce + (1 - alpha) * standard_ce","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T17:17:17.846359Z","iopub.execute_input":"2025-07-21T17:17:17.846596Z","iopub.status.idle":"2025-07-21T17:17:17.861154Z","shell.execute_reply.started":"2025-07-21T17:17:17.846574Z","shell.execute_reply":"2025-07-21T17:17:17.860469Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Function to evaluate model\ndef evaluate_model(model, data_loader, desc=\"Evaluating\"):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in tqdm(data_loader, desc=desc, leave=False):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    return correct / total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T17:17:17.861937Z","iopub.execute_input":"2025-07-21T17:17:17.862199Z","iopub.status.idle":"2025-07-21T17:17:17.875425Z","shell.execute_reply.started":"2025-07-21T17:17:17.862177Z","shell.execute_reply":"2025-07-21T17:17:17.874907Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Train the teacher model \nteacher_model = TeacherModel().to(device)\noptimizer = optim.Adam(teacher_model.parameters())\ncriterion = nn.CrossEntropyLoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T17:17:17.876084Z","iopub.execute_input":"2025-07-21T17:17:17.876276Z","iopub.status.idle":"2025-07-21T17:17:17.892111Z","shell.execute_reply.started":"2025-07-21T17:17:17.876262Z","shell.execute_reply":"2025-07-21T17:17:17.891477Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"print(\"Training teacher model...\")\nfor epoch in range(5):\n    teacher_model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/5')\n    for images, labels in pbar:\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = teacher_model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n    \n    avg_loss = running_loss / len(train_loader)\n    epoch_acc = correct / total \n    \n    print(f\"Epoch {epoch+1}/5 - Loss: {avg_loss:.4f}, Accuracy: {epoch_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T17:17:17.892813Z","iopub.execute_input":"2025-07-21T17:17:17.893167Z","iopub.status.idle":"2025-07-21T17:18:14.596730Z","shell.execute_reply.started":"2025-07-21T17:17:17.893144Z","shell.execute_reply":"2025-07-21T17:18:14.596095Z"}},"outputs":[{"name":"stdout","text":"Training teacher model...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5: 100%|██████████| 469/469 [00:11<00:00, 41.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5 - Loss: 0.1918, Accuracy: 0.9414\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 100%|██████████| 469/469 [00:11<00:00, 41.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/5 - Loss: 0.0493, Accuracy: 0.9849\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 100%|██████████| 469/469 [00:11<00:00, 41.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/5 - Loss: 0.0328, Accuracy: 0.9897\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 100%|██████████| 469/469 [00:11<00:00, 40.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/5 - Loss: 0.0249, Accuracy: 0.9921\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 100%|██████████| 469/469 [00:11<00:00, 41.73it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 5/5 - Loss: 0.0205, Accuracy: 0.9934\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"teacher_acc = evaluate_model(teacher_model, test_loader, \"Testing teacher\")\nprint(f\"Teacher model test accuracy: {teacher_acc:.4f}\")\n# Get teacher model size\ntorch.save(teacher_model.state_dict(), 'teacher_model.pth')\nteacher_size = os.path.getsize('teacher_model.pth') / (1024 * 1024)  # Size in MB\nprint(f\"Teacher model size: {teacher_size:.2f} MB\")\n\n# Measure teacher inference time \nstart_time = time.time()\nteacher_model.eval()\nwith torch.no_grad():\n    test_subset = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n    for images, _ in tqdm(test_subset, desc=\"Teacher inference\", leave=False):\n        images = images.to(device)\n        teacher_model(images)\n        break  # Only process 1000 samples\nteacher_inference_time = time.time() - start_time\nprint(f\"Teacher inference time (1000 samples): {teacher_inference_time:.4f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T17:18:14.597372Z","iopub.execute_input":"2025-07-21T17:18:14.597637Z","iopub.status.idle":"2025-07-21T17:18:16.438605Z","shell.execute_reply.started":"2025-07-21T17:18:14.597619Z","shell.execute_reply":"2025-07-21T17:18:16.437841Z"}},"outputs":[{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"Teacher model test accuracy: 0.9915\nTeacher model size: 1.75 MB\n","output_type":"stream"},{"name":"stderr","text":"                                                         ","output_type":"stream"},{"name":"stdout","text":"Teacher inference time (1000 samples): 0.1585 seconds\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Precompute teacher logits for training with tqdm\nprint(\"Computing teacher logits...\")\nteacher_logits = []\nteacher_model.eval()\nwith torch.no_grad():\n    for images, _ in tqdm(train_loader, desc=\"Computing logits\", leave=False):\n        images = images.to(device)\n        logits = teacher_model(images)\n        teacher_logits.append(logits.cpu())\nteacher_logits = torch.cat(teacher_logits, dim=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T17:18:16.439384Z","iopub.execute_input":"2025-07-21T17:18:16.439668Z","iopub.status.idle":"2025-07-21T17:18:26.529253Z","shell.execute_reply.started":"2025-07-21T17:18:16.439645Z","shell.execute_reply":"2025-07-21T17:18:26.528685Z"}},"outputs":[{"name":"stdout","text":"Computing teacher logits...\n","output_type":"stream"},{"name":"stderr","text":"                                                                   \r","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Train the student model with knowledge distillation and tqdm\nstudent_model = StudentModel().to(device)\noptimizer = optim.Adam(student_model.parameters())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T17:18:26.529948Z","iopub.execute_input":"2025-07-21T17:18:26.530153Z","iopub.status.idle":"2025-07-21T17:18:26.536124Z","shell.execute_reply.started":"2025-07-21T17:18:26.530137Z","shell.execute_reply":"2025-07-21T17:18:26.535641Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Train the student model with knowledge distillation\nprint(\"\\nTraining student model with knowledge distillation...\")\nfor epoch in range(5):\n    student_model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Student Epoch {epoch+1}/5')\n    for i, (images, labels) in pbar:\n        images, labels = images.to(device), labels.to(device)\n        batch_logits = teacher_logits[i * 128:(i + 1) * 128].to(device)\n        \n        optimizer.zero_grad()\n        outputs = student_model(images)\n        loss = distillation_loss(outputs, labels, batch_logits)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        \n    avg_loss = running_loss / len(train_loader)\n    epoch_acc = correct / total\n    print(f\"Student Epoch {epoch+1}/5 - Loss: {avg_loss:.4f}, Accuracy: {epoch_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T17:18:26.536948Z","iopub.execute_input":"2025-07-21T17:18:26.537179Z","iopub.status.idle":"2025-07-21T17:19:22.235396Z","shell.execute_reply.started":"2025-07-21T17:18:26.537155Z","shell.execute_reply":"2025-07-21T17:19:22.234664Z"}},"outputs":[{"name":"stdout","text":"\nTraining student model with knowledge distillation...\n","output_type":"stream"},{"name":"stderr","text":"Student Epoch 1/5: 100%|██████████| 469/469 [00:10<00:00, 43.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Student Epoch 1/5 - Loss: 16.8721, Accuracy: 0.6451\n","output_type":"stream"},{"name":"stderr","text":"Student Epoch 2/5: 100%|██████████| 469/469 [00:10<00:00, 43.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Student Epoch 2/5 - Loss: 16.7272, Accuracy: 0.8600\n","output_type":"stream"},{"name":"stderr","text":"Student Epoch 3/5: 100%|██████████| 469/469 [00:11<00:00, 41.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Student Epoch 3/5 - Loss: 16.7064, Accuracy: 0.9103\n","output_type":"stream"},{"name":"stderr","text":"Student Epoch 4/5: 100%|██████████| 469/469 [00:11<00:00, 40.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Student Epoch 4/5 - Loss: 16.6718, Accuracy: 0.9276\n","output_type":"stream"},{"name":"stderr","text":"Student Epoch 5/5: 100%|██████████| 469/469 [00:11<00:00, 41.72it/s]","output_type":"stream"},{"name":"stdout","text":"Student Epoch 5/5 - Loss: 16.6715, Accuracy: 0.9335\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"student_acc = evaluate_model(student_model, test_loader, \"Testing student\")\nprint(f\"Student model test accuracy: {student_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T17:19:22.236036Z","iopub.execute_input":"2025-07-21T17:19:22.236265Z","iopub.status.idle":"2025-07-21T17:19:23.941902Z","shell.execute_reply.started":"2025-07-21T17:19:22.236248Z","shell.execute_reply":"2025-07-21T17:19:23.941255Z"}},"outputs":[{"name":"stderr","text":"                                                                ","output_type":"stream"},{"name":"stdout","text":"Student model test accuracy: 0.9484\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# Get student model size\ntorch.save(student_model.state_dict(), 'student_model.pth')\nstudent_size = os.path.getsize('student_model.pth') / (1024 * 1024)  # Size in MB\nprint(f\"Student model size: {student_size:.2f} MB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T17:19:23.942627Z","iopub.execute_input":"2025-07-21T17:19:23.942856Z","iopub.status.idle":"2025-07-21T17:19:23.949053Z","shell.execute_reply.started":"2025-07-21T17:19:23.942838Z","shell.execute_reply":"2025-07-21T17:19:23.948573Z"}},"outputs":[{"name":"stdout","text":"Student model size: 0.39 MB\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# Measure student inference time with tqdm\nstart_time = time.time()\nstudent_model.eval()\nwith torch.no_grad():\n    test_subset = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n    for images, _ in tqdm(test_subset, desc=\"Student inference\", leave=False):\n        images = images.to(device)\n        student_model(images)\n        break  # Only process 1000 samples\nstudent_inference_time = time.time() - start_time\nprint(f\"Student inference time (1000 samples): {student_inference_time:.4f} seconds\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T17:19:23.949879Z","iopub.execute_input":"2025-07-21T17:19:23.950495Z","iopub.status.idle":"2025-07-21T17:19:24.139410Z","shell.execute_reply.started":"2025-07-21T17:19:23.950477Z","shell.execute_reply":"2025-07-21T17:19:24.138773Z"}},"outputs":[{"name":"stderr","text":"                                                         ","output_type":"stream"},{"name":"stdout","text":"Student inference time (1000 samples): 0.1694 seconds\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"\n# Summary of benefits\nprint(\"\\nKnowledge Distillation Benefits:\")\nprint(f\"- Teacher Accuracy: {teacher_acc:.4f}, Student Accuracy: {student_acc:.4f}\")\nprint(f\"- Model Size Reduction: {(1 - student_size / teacher_size) * 100:.2f}%\")\nprint(f\"- Inference Time Reduction: {(1 - student_inference_time / teacher_inference_time) * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T17:19:24.140061Z","iopub.execute_input":"2025-07-21T17:19:24.140287Z","iopub.status.idle":"2025-07-21T17:19:24.144784Z","shell.execute_reply.started":"2025-07-21T17:19:24.140270Z","shell.execute_reply":"2025-07-21T17:19:24.144252Z"}},"outputs":[{"name":"stdout","text":"\nKnowledge Distillation Benefits:\n- Teacher Accuracy: 0.9915, Student Accuracy: 0.9484\n- Model Size Reduction: 77.89%\n- Inference Time Reduction: -6.90%\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}